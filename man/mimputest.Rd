% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mimputest.R
\name{mimputest}
\alias{mimputest}
\title{Multiple imputation or estimation of missing data with random forests.}
\usage{
mimputest(
  data,
  model = NULL,
  n = 5L,
  sampler = c("gibbs", "missforest"),
  prediction_type = c("inbag", "bagged", "doove"),
  fn_init = impute_naive_by_sample,
  stop_measure = measure_degenerate,
  loop_limit = 10L,
  overrides = list(),
  clean_step = list(),
  keep_forests = FALSE,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{data}{data.frame: an incomplete data set of numeric, logical, integer,
factor, or ordered data - one row per observation, one column per variable.}

\item{model}{matrix (named): the included variables for each random forest,
with one row per random forest (to impute the variable named by the row), one
column for each variable (named), with elements equal to 1 (or \code{TRUE}) to
include, and 0 (or \code{FALSE}) to exclude a variable. Default is a matrix where
each row is a variable with missing values, and all other variables that are
not entirely missing are included, with rows in order of least to most
missing.}

\item{n}{integer: the number of imputed datasets to generate via independent
chains.}

\item{sampler}{character: the type of sampling loop to use, either \code{'gibbs'},
where each forest is trained on the most recently imputed values of
predictors, or \code{'missforest'}, where each forest is trained on the imputed
values of predictors from the previous iteration.}

\item{prediction_type}{character: the method for drawing values from the
random forests; \code{'inbag'} is the default, \code{'doove'} is the approach in
'mice', and \code{'bagged'} is used by 'missForest' (see details and references).}

\item{fn_init}{function: a function or character (passed to \code{\link[=match.fun]{match.fun()}}) to
initialise the missing values prior to the sampler loop given two arguments
\code{data} and \code{indicator}; default is to sample complete cases using
\code{\link[=impute_naive_by_sample]{impute_naive_by_sample()}}, see details for other options.}

\item{stop_measure}{function: a function or character (passed to
\code{\link[=match.fun]{match.fun()}}) that provides some measure of difference between consecutive
iterations of the sampler loop, takes four arguments \code{x_sample}, \code{y_sample},
\code{data} and \code{indicator}; the first two provide the imputed values to compare,
while the latter are a completed dataset and the indicator of the location of
missing values; default is \code{\link[=measure_degenerate]{measure_degenerate()}} which stops when
\code{loop_limit} is reached, see details for more measures.}

\item{loop_limit}{integer: non-negative upper limit on the number of
iterations to perform in any single chain; default is 10.}

\item{overrides}{list (named): additional parameters to pass to
\code{\link[literanger:train]{literanger::train()}} for the corresponding (named) variable.}

\item{clean_step}{list (named): functions to enforce constraints and
conditions on imputed values, see details.}

\item{keep_forests}{logical: whether to store each forest returned by
literanger used to generate each imputed dataset (default \code{FALSE}).}

\item{verbose}{logical: whether to provide progress bars for each chain.}

\item{...}{additional arguments passed to \code{\link[literanger:train]{literanger::train()}} for all
variables e.g. \code{n_tree=5} to use five trees in each forest (default is 10).}
}
\value{
list (named, class \code{mimputest}): the result from each sampler along
with information about the call and the parameters used to run the samplers,
the convergence measures and status, summary statistics for each sampler, and
some record-keeping items. The named items are:
\itemize{
\item \code{call} (call): the original call as given by \code{match.call}.
\item \code{data} (data.frame): the data as passed except for excluded variables.
\item \code{model}, \code{n}, \code{fn_init}, \code{stop_measure}, \code{sampler}, \code{prediction_type}:
the values of the arguments that were used to get the final output.
\item \code{indicator} (list): the indicator of missing status (\code{TRUE} for missing)
for each variable in \code{data}.
\item \code{imputed} (list): the imputed values from each sampler; each item
contains the values for the iterations from a single sampler as a nested
list; within each iteration, the imputed values are stored on a
per-variable basis and within each variable they appear in the same order
as the missing cases in the data (for the variable).
\item \code{statistics} (list): the statistics and frequency of imputed values as
data.frames; statistics are given by sampler, iteration, and variable
(and for frequency, by value).
\item \code{converged} (logical): the indicator of convergence status for each
sampler (\code{TRUE} when \code{\link[=measure_degenerate]{measure_degenerate()}} is used and no error
occurred).
\item \code{stop_measures}: the measures recorded for assessing convergence (can
ignore when using \code{\link[=measure_degenerate]{measure_degenerate()}}) for each sampler.
\item \code{oob_error} (list): the out-of-bag error of the random forests for each
sampler as data.frames; values are given by iteration and variable.
\item \code{forests} (list): the random forests for each variable from the final
iteration of each sampler if \code{keep_forests=TRUE}, otherwise each item is
\code{NULL} (default).
\item \code{seed} (integer): the seed supplied to \code{\link[=set.seed]{set.seed()}} prior to each
sampler call.
\item \code{package_version} (character): version of \code{mimputest} used.
\item \code{timestamp} (POSIXct): the time when the output was returned.
}
}
\description{
Generate datasets with imputed values for missing cases using the Multiple
Imputation via Chained Equations (MICE) procedure of Van Buuren and
Groothuis-Oudshorn (2012), using random forests with predictions drawn as
proposed by Bartlett (2014). Alternatively, via this interface, estimates of
the missing cases can be generated via the missForest algorithm of Stekhoven
and Buehlmann (2012).
}
\details{
The MICE algorithm for multiple imputation generates a fixed number of
complete datasets, which can be set via the \code{n} argument. Each completed
dataset is the end point of one run of an iterative procedure (which we call
a 'sampler' a.k.a 'chain') that (randomly) draws intermediate datasets up
until it is deemed to have converged. Each completed dataset is the result
of an independent sampler. Typically the number of iterations per sampler is
fixed, equal to the \code{loop_limit} argument, and assessment of convergence is
performed in post. When estimation (rather than imputation) is being
performed, as in missForest, only a single sampler is needed (\code{n=1}), and in
addition to the limit on the number of iterations, a stopping criterion is
assessed, which can be set via the \code{stop_measure} argument. The default
measure is degenerate, and stops the sampler at \code{loop_limit} iterations. For
the 'missForest' criterion, \code{\link[=measure_stekhoven_2012]{measure_stekhoven_2012()}} is supplied alongside
a new measure called \code{\link[=measure_correlation]{measure_correlation()}}; when these are employed the
sampler either stops when the criterion is met or when \code{loop_limit} is
reached - whichever occurs first.

The structure of the loop in a sampler is broadly consistent between multiple
imputation and 'missForest' estimation. At each iteration a dataset is
generated by (sequentially) training random forests on observed values of
variables and then drawing predictions for missing cases. The variables
included in each random forest are determined by the \code{model} argument; which
is a matrix of indicators (0 or 1) where each row is a 'response' and each
column is a 'predictor' in the random forest. The order in which models are
trained (and values drawn) is taken from the order of the rows in \code{model}.
The default \code{model} includes all covariates and trains in order of least to
most missing.

Each sampler requires an initial complete dataset which is constructed using
the function supplied as \code{fn_init}. This function should take an incomplete
dataset and the location of the missing cases and return a complete dataset.
For example, missing cases could be replaced with a random sample of observed
values. This is the default approach here (and also in 'mice' package), and
is provided via the \code{\link[=impute_naive_by_sample]{impute_naive_by_sample()}} function. Alternatively, for
'missForest', the most-frequent-value or mean could be used, as implemented
in \code{\link[=impute_naive_by_aggregate]{impute_naive_by_aggregate()}}.

The \code{sampler} argument selects the type of sampling performed, the default
\code{sampler='gibbs'} corresponds to the sampler for 'mice', while
\code{sampler='missforest'} will use 'missForest's sampling. The difference
between the two is when drawn values are used in training - for the former
the most recently drawn value is used immediately, while for the latter they
are not used until the next iteration in the sampler loop.

The 'mice' package draws values from random forests using the approach of
Doove et al, 2014. Compared to the traditional prediction of a random forest
(which is bagged, Breiman 2001), the 'mice' approach leads to better coverage
and bias properties for pooled estimates from the completed (imputed)
datasets. Bartlett (2014) proposed a variation on this approach that should
improve coverage and bias further. This latter prediction type is the default
(\code{'inbag'}), while 'mice's approach can be selected via
\code{prediction_type='doove'}. 'missForest', being an estimation procedure, uses
the original random forest prediction (\code{prediction_type='bagged'}).

Forests employ either classification or regression trees depending on the
predictor type. For factors (including ordered), logical, and integers; a
classification tree is used. For numeric values, regression trees. The
default number of trees used is 10 (in each forest). The number of variables
drawn for evaluation at each node, during training, are the default values
from \code{\link[literanger:train]{literanger::train()}} (the \code{n_try} argument). The minimum size of a leaf
node in the forest has default value of 5. One a per-variable basis any
argument can be over-ridden using the \code{overrides} argument. To override the
default argument for all trees, use (named) \code{...} arguments.

After the missing values have been drawn for a variable a post-processing
'cleaning' step can be applied. These steps are provided on a per-variable
basis in the \code{clean_step} argument. The user provides (for any variable)
functions that accept arguments named \code{data} and \code{imputed} which,
respectively, contain the data-set for the rows with missing values as used
in training the random forest and the imputed values drawn from the (trained)
random forest. The functions should return a vector of the same length as
\code{imputed} with the clean values. The cleaning step can ensure that known (a
priori) constraints on the value are respected.

This function returns an object (list) with class \code{mimputest} with the
imputed values and summary statistics for assessing convergence. This can be
converted to a \code{mice::mids} object with \code{\link[=as_mids]{as_mids()}}. The information returned
includes the call, the data (restricted to the variables used), the location
of missing data, the init function, convergence measures and status,
prediction type, sampler type, and the seeds used prior to each chain. The
trained random forests from the final iteration of each chain are returned if
\code{keep_forests=TRUE} (default is \code{FALSE}).
}
\references{
\itemize{
\item Bartlett, J. (2014, 6-11 July). \emph{Methodology for multiple imputation for
missing data in electronic health record data} [Conference
presentation]. International Biometric Conference, Florence, TOS, Italy.
\href{https://web.archive.org/web/20190819140612/http://thestatsgeek.com/wp-content/uploads/2014/09/RandomForestImpBiometricsConf.pdf}{Archived 2019-08-19}.
\item Breiman, L. (2001). Random forests. \emph{Machine Learning}, \emph{45}, 5-32.
\doi{10.1023/A:1010933404324}.
\item Doove, L.L., Van Buuren, S., & Dusseldorp, E. (2014). Recursive
partitioning for missing data imputation in the presence of interaction
\doi{10.1016/j.csda.2013.10.025}.
\item Stekhoven, D. J. & Buehlmann, P. (2012). MissForest--non-parametric
missing value imputation for mixed-type data. \emph{Bioinformatics}, \emph{28}(1),
112-118. \doi{10.1093/bioinformatics/btr597}.
\item Van Buuren, S. & Groothuis-Oudshoorn, K. (2011). mice: Multivariate
Imputation by Chained Equations in R. \emph{Journal of Statistical Software},
\emph{45}(3), 1-67. \doi{10.18637/jss.v045.i03}.
}
}
\seealso{
\code{\link[=as_mids]{as_mids()}} \code{\link[=impute_naive_by_sample]{impute_naive_by_sample()}} \code{\link[=measure_degenerate]{measure_degenerate()}}
\code{\link[=sampler_loop]{sampler_loop()}} \code{\link[literanger:train]{literanger::train()}}
}
\author{
Stephen Wade \href{mailto:stephematician@gmail.com}{stephematician@gmail.com}
}
