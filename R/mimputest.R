# SPDX-FileCopyrightText: 2023 Stephen Wade <stephematician@gmail.com>
# SPDX-License-Identifier: MIT

#' Multiple imputation or estimation of missing data with random forests.
#'
#' Generate datasets with imputed values for missing cases using the Multiple
#' Imputation via Chained Equations (MICE) procedure of Van Buuren and
#' Groothuis-Oudshorn (2012), using random forests with predictions drawn as
#' proposed by Bartlett (2014). Alternatively, via this interface, estimates of
#' the missing cases can be generated via the missForest algorithm of Stekhoven
#' and Buehlmann (2012).
#'
#' The MICE algorithm for multiple imputation generates a fixed number of
#' complete datasets, which can be set via the `n` argument. Each completed
#' dataset is the end point of one run of an iterative procedure (which we call
#' a 'sampler' a.k.a 'chain') that (randomly) draws intermediate datasets up
#' until it is deemed to have converged. Each completed dataset is the result
#' of an independent sampler. Typically the number of iterations per sampler is
#' fixed, equal to the `loop_limit` argument, and assessment of convergence is
#' performed in post. When estimation (rather than imputation) is being
#' performed, as in missForest, only a single sampler is needed (`n=1`), and in
#' addition to the limit on the number of iterations, a stopping criterion is
#' assessed, which can be set via the `stop_measure` argument. The default
#' measure is degenerate, and stops the sampler at `loop_limit` iterations. For
#' the 'missForest' criterion, [measure_stekhoven_2012()] is supplied alongside
#' a new measure called [measure_correlation()]; when these are employed the
#' sampler either stops when the criterion is met or when `loop_limit` is
#' reached - whichever occurs first.
#'
#' The structure of the loop in a sampler is broadly consistent between multiple
#' imputation and 'missForest' estimation. At each iteration a dataset is
#' generated by (sequentially) training random forests on observed values of
#' variables and then drawing predictions for missing cases. The variables
#' included in each random forest are determined by the `model` argument; which
#' is a matrix of indicators (0 or 1) where each row is a 'response' and each
#' column is a 'predictor' in the random forest. The order in which models are
#' trained (and values drawn) is taken from the order of the rows in `model`.
#' The default `model` includes all covariates and trains in order of least to
#' most missing.
#'
#' Each sampler requires an initial complete dataset which is constructed using
#' the function supplied as `fn_init`. This function should take an incomplete
#' dataset and the location of the missing cases and return a complete dataset.
#' For example, missing cases could be replaced with a random sample of observed
#' values. This is the default approach here (and also in 'mice' package), and
#' is provided via the [impute_naive_by_sample()] function. Alternatively, for
#' 'missForest', the most-frequent-value or mean could be used, as implemented
#' in [impute_naive_by_aggregate()].
#'
#' The `sampler` argument selects the type of sampling performed, the default
#' `sampler='gibbs'` corresponds to the sampler for 'mice', while
#' `sampler='missforest'` will use 'missForest's sampling. The difference
#' between the two is when drawn values are used in training - for the former
#' the most recently drawn value is used immediately, while for the latter they
#' are not used until the next iteration in the sampler loop.
#'
#' The 'mice' package draws values from random forests using the approach of
#' Doove et al, 2014. Compared to the traditional prediction of a random forest
#' (which is bagged, Breiman 2001), the 'mice' approach leads to better coverage
#' and bias properties for pooled estimates from the completed (imputed)
#' datasets. Bartlett (2014) proposed a variation on this approach that should
#' improve coverage and bias further. This latter prediction type is the default
#' (`'inbag'`), while 'mice's approach can be selected via
#' `prediction_type='doove'`. 'missForest', being an estimation procedure, uses
#' the original random forest prediction (`prediction_type='bagged'`).
#'
#' Forests employ either classification or regression trees depending on the
#' predictor type. For factors (including ordered), logical, and integers; a
#' classification tree is used. For numeric values, regression trees. The
#' default number of trees used is 10 (in each forest). The number of variables
#' drawn for evaluation at each node, during training, are the default values
#' from [literanger::train()] (the `n_try` argument). The minimum size of a leaf
#' node in the forest has default value of 5. One a per-variable basis any
#' argument can be over-ridden using the `overrides` argument. To override the
#' default argument for all trees, use (named) `...` arguments.
#'
#' After the missing values have been drawn for a variable a post-processing
#' 'cleaning' step can be applied. These steps are provided on a per-variable
#' basis in the `clean_step` argument. The user provides (for any variable)
#' functions that accept arguments named `data` and `imputed` which,
#' respectively, contain the data-set for the rows with missing values as used
#' in training the random forest and the imputed values drawn from the (trained)
#' random forest. The functions should return a vector of the same length as
#' `imputed` with the clean values. The cleaning step can ensure that known (a
#' priori) constraints on the value are respected.
#'
#' This function returns an object (list) with class `mimputest` with the
#' imputed values and summary statistics for assessing convergence. This can be
#' converted to a `mice::mids` object with [as_mids()]. The information returned
#' includes the call, the data (restricted to the variables used), the location
#' of missing data, the init function, convergence measures and status,
#' prediction type, sampler type, and the seeds used prior to each chain. The
#' trained random forests from the final iteration of each chain are returned if
#' `keep_forests=TRUE` (default is `FALSE`).
#'
#' @param data data.frame: an incomplete data set of numeric, logical, integer,
#' factor, or ordered data - one row per observation, one column per variable.
#' @param model matrix (named): the included variables for each random forest,
#' with one row per random forest (to impute the variable named by the row), one
#' column for each variable (named), with elements equal to 1 (or `TRUE`) to
#' include, and 0 (or `FALSE`) to exclude a variable. Default is a matrix where
#' each row is a variable with missing values, and all other variables that are
#' not entirely missing are included, with rows in order of least to most
#' missing.
#' @param n integer: the number of imputed datasets to generate via independent
#' chains.
#' @param sampler character: the type of sampling loop to use, either `'gibbs'`,
#' where each forest is trained on the most recently imputed values of
#' predictors, or `'missforest'`, where each forest is trained on the imputed
#' values of predictors from the previous iteration.
#' @param prediction_type character: the method for drawing values from the
#' random forests; `'inbag'` is the default, `'doove'` is the approach in
#' 'mice', and `'bagged'` is used by 'missForest' (see details and references).
#' @param fn_init function: a function or character (passed to [match.fun()]) to
#' initialise the missing values prior to the sampler loop given two arguments
#' `data` and `indicator`; default is to sample complete cases using
#' [impute_naive_by_sample()], see details for other options.
#' @param stop_measure function: a function or character (passed to
#' [match.fun()]) that provides some measure of difference between consecutive
#' iterations of the sampler loop, takes four arguments `x_sample`, `y_sample`,
#' `data` and `indicator`; the first two provide the imputed values to compare,
#' while the latter are a completed dataset and the indicator of the location of
#' missing values; default is [measure_degenerate()] which stops when
#' `loop_limit` is reached, see details for more measures.
#' @param loop_limit integer: non-negative upper limit on the number of
#' iterations to perform in any single chain; default is 10.
#' @param overrides list (named): additional parameters to pass to
#' [literanger::train()] for the corresponding (named) variable.
#' @param clean_step list (named): functions to enforce constraints and
#' conditions on imputed values, see details.
#' @param keep_forests logical: whether to store each forest returned by
#' literanger used to generate each imputed dataset (default `FALSE`).
#' @param verbose logical: whether to provide progress bars for each chain.
#' @param ... additional arguments passed to [literanger::train()] for all
#' variables e.g. `n_tree=5` to use five trees in each forest (default is 10).
#'
#' @return list (named, class `mimputest`): the result from each sampler along
#' with information about the call and the parameters used to run the samplers,
#' the convergence measures and status, summary statistics for each sampler, and
#' some record-keeping items. The named items are:
#' -   `call` (call): the original call as given by `match.call`.
#' -   `data` (data.frame): the data as passed except for excluded variables.
#' -   `model`, `n`, `fn_init`, `stop_measure`, `sampler`, `prediction_type`:
#'     the values of the arguments that were used to get the final output.
#' -   `indicator` (list): the indicator of missing status (`TRUE` for missing)
#'     for each variable in `data`.
#' -   `imputed` (list): the imputed values from each sampler; each item
#'     contains the values for the iterations from a single sampler as a nested
#'     list; within each iteration, the imputed values are stored on a
#'     per-variable basis and within each variable they appear in the same order
#'     as the missing cases in the data (for the variable).
#' -   `statistics` (list): the statistics and frequency of imputed values as
#'     data.frames; statistics are given by sampler, iteration, and variable
#'     (and for frequency, by value).
#' -   `converged` (logical): the indicator of convergence status for each
#'     sampler (`TRUE` when [measure_degenerate()] is used and no error
#'     occurred).
#' -   `stop_measures`: the measures recorded for assessing convergence (can
#'     ignore when using [measure_degenerate()]) for each sampler.
#' -   `oob_error` (list): the out-of-bag error of the random forests for each
#'     sampler as data.frames; values are given by iteration and variable.
#' -   `forests` (list): the random forests for each variable from the final
#'     iteration of each sampler if `keep_forests=TRUE`, otherwise each item is
#'     `NULL` (default).
#' -   `seed` (integer): the seed supplied to [set.seed()] prior to each
#'      sampler call.
#' -   `package_version` (character): version of `mimputest` used.
#' -   `timestamp` (POSIXct): the time when the output was returned.
#'
#' @seealso [as_mids()] [impute_naive_by_sample()] [measure_degenerate()]
#' [sampler_loop()] [literanger::train()]
#'
#' @references
#' -   Bartlett, J. (2014, 6-11 July). _Methodology for multiple imputation for
#'     missing data in electronic health record data_ \[Conference
#'     presentation\]. International Biometric Conference, Florence, TOS, Italy.
#'     [Archived 2019-08-19][bartlett2014_archive].
#' -   Breiman, L. (2001). Random forests. _Machine Learning_, _45_, 5-32.
#'     \doi{10.1023/A:1010933404324}.
#' -   Doove, L.L., Van Buuren, S., & Dusseldorp, E. (2014). Recursive
#'     partitioning for missing data imputation in the presence of interaction
#'     \doi{10.1016/j.csda.2013.10.025}.
#' -   Stekhoven, D. J. & Buehlmann, P. (2012). MissForest--non-parametric
#'     missing value imputation for mixed-type data. _Bioinformatics_, _28_(1),
#'     112-118. \doi{10.1093/bioinformatics/btr597}.
#' -   Van Buuren, S. & Groothuis-Oudshoorn, K. (2011). mice: Multivariate
#'     Imputation by Chained Equations in R. _Journal of Statistical Software_,
#'     _45_(3), 1-67. \doi{10.18637/jss.v045.i03}.
#'
#' [bartlett2014_archive]: https://web.archive.org/web/20190819140612/http://thestatsgeek.com/wp-content/uploads/2014/09/RandomForestImpBiometricsConf.pdf
#'
#' @author Stephen Wade <stephematician@gmail.com>
#'
#' @importFrom rlang call2 call_modify list2
#' @importFrom utils modifyList packageVersion tail
#' @export
#' @md
mimputest <- function(data, model=NULL, n=5L, sampler=c('gibbs', 'missforest'),
                      prediction_type=c('inbag', 'bagged', 'doove'),
                      fn_init=impute_naive_by_sample,
                      stop_measure=measure_degenerate,
                      loop_limit=10L, overrides=list(), clean_step=list(),
                      keep_forests=FALSE, verbose=FALSE, ...) {

    lr_train_args <- modifyList(
      # default arguments to literanger::train
        list(min_leaf_n_sample=5, n_tree=10),
      # user-provided arguments
        rlang::list2(...)
    )

    fn_init <- match.fun(fn_init)
    stop_measure <- match.fun(stop_measure)
    sampler <- match.arg(sampler)
    prediction_type <- match.arg(prediction_type)

  # check_args() may not preserve the pseudo-rng so store and reset
    seed <- .Random.seed
    check_args(
        data=data, model=model, n=n, fn_init=fn_init,
        stop_measure=stop_measure, loop_limit=loop_limit, overrides=overrides,
        clean_step=clean_step, keep_forests=keep_forests, verbose=verbose
    )
    .Random.seed <- seed

    n_obs <- nrow(data)

    if (!identical(round(n), as.numeric(n)))
        warning('Non-integer value of \'n\' supplied.')

    if (!identical(round(loop_limit), as.numeric(loop_limit)))
        warning('Non-integer value of \'loop_limit\' supplied.')

    if (inherits(data, 'grouped_df'))
        warning('Groups in \'data\' will be ignored.')

  # store location of missing data as list
    indicator <- lapply(data, is.na)

  # filter completely missing variables
    n_miss <- sapply(indicator, sum)
    if (any(n_miss == n_obs))
        warning('Excluding the following entirely missing data in \'data\': ',
                paste(names(n_miss)[n_miss == n_obs], collapse=', '), '.')

    included <- names(n_miss)[n_miss != n_obs]
    indicator <- indicator[included]
    n_miss <- n_miss[included]

  # default model includes all covariates, and imputes in the order from least
  # to most missing values
    if (is.null(model)) {
        model <- matrix(1, nrow=length(included), ncol=length(included),
                        dimnames=list(included, included))
        diag(model) <- 0
        model <- model[order(n_miss)[n_miss > 0], , drop=FALSE]
    }
  # convert integers and logical values to factors or ordered
    to_categorical <- sapply(data, is.integer) | sapply(data, is.logical)
    inv_tform_categorical <- lapply(data[to_categorical],
                                    make_inv_tform_categorical)
  # fn_init(data, indicator) will construct the initial values for missing data
  # for a single chain
    call_init <- rlang::call2(
        fn_init, data=data[included], indicator=indicator
    )
    call_lr_train <- rlang::call_modify(
        rlang::call2(literanger::train, verbose=verbose),
        !!! lr_train_args
    )

    each_seed <- sample.int(.Machine$integer.max, size=n, replace=FALSE)

    result <- list()

    for (j in seq_len(n)) {

        set.seed(each_seed[j])

        data_j <- eval(call_init)
        msgs <- is_valid_initial_state(data_j, data[included])
        if (length(msgs) > 0)
            stop('The following initial data conditions failed: ',
                 paste(msgs, collapse='; '), '.')

        data_j[to_categorical] %<>% lapply(tform_categorical)

        result[[j]] <- sampler_loop(
            data=data_j, model=model, indicator=indicator,
            call_lr_train=call_lr_train, sampler=sampler,
            prediction_type=prediction_type,
            stop_measure=stop_measure, loop_limit=loop_limit,
            overrides=overrides, clean_step=clean_step,
            keep_forests=keep_forests, chain_id=j, verbose=verbose
        )

      # convert imputed values in each chain back to integer/logical
        result[[j]]$imputed <- lapply(
            result[[j]]$imputed, apply_inv_tform_categorical,
            inv_tform_categorical=inv_tform_categorical
        )

    }

    structure(
        list(
          # input parameters
            call=match.call(),
            data=data[included], model=model, n=n, fn_init=fn_init,
            stop_measure=stop_measure, sampler=sampler,
            prediction_type=prediction_type,
          # location of missing cases, imputed values, and summary statistics
            indicator=indicator, n_miss=n_miss,
            imputed=lapply(result, '[[', 'imputed') %>% sapply(tail, 1),
            statistics=lapply(result, post_process),
            converged=sapply(result, '[[', 'converged'),
          # TODO: stop measures
            measures=lapply(result, '[[', 'measures'),
            oob_error=lapply(result, '[[', 'oob_error'),
          # keep forests if requested
            forests=lapply(result, '[[', 'forests'),
          # additional data for reproduction
            seed=each_seed, package_version=packageVersion('mimputest'),
            timestamp=Sys.time()
        ),
        class="mimputest"
    )

}

